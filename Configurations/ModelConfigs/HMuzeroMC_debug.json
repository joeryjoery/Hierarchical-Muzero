{
  "name": "Hierarchical_Base",
  "algorithm": "HIERARCHICAL_MUZERO",
  "architecture": "Hierarchical_Gym",
  "goal_architecture": "Gym",
  "action_architecture": "Gym",

  "args": {
    "num_selfplay_iterations": 500,
    "num_episodes": 2,
    "num_gradient_steps": 4,
    "max_episode_moves": 500,
    "max_trial_moves": 500,
    "pitting": true,
    "pitting_trials": 10,
    "pit_acceptance_ratio": 0.0,
    "dirichlet_alpha": 0.3,
    "exploration_fraction": 0.2,
    "max_buffer_size": 200000,
    "num_MCTS_sims": 11,
    "prioritize": false,
    "prioritize_alpha": 0.5,
    "prioritize_beta": 1,
    "latent_decoder": false,
    "plan_actions": false,
    "plan_goals": true,
    "goal_error": 0.01,
    "goal_horizon": 5,
    "subgoal_testing": 0.0,
    "K": 3,
    "n_steps": 10,
    "c_pw": 1,
    "alpha_pw": 0.5,
    "c1": 1.25,
    "c2": 19652,
    "gamma": 0.997,

    "minimum_reward": null,
    "maximum_reward": null,

    "checkpoint": "./out/hierarchical/pendulum/",
    "load_model": false,
    "load_folder_file": ["./out/hierarchical/pendulum/", "latest.pth.tar"],
    "selfplay_buffer_window": 10,

    "temperature_schedule": {
      "method": "stepwise",
      "by_weight_update": true,
      "schedule_points": [[0, 1]]
    }
  },

  "net_args": {
    "optimizer": {
      "method": "adam",
      "lr_init": 0.02,
      "momentum": 0.9
    },
    "goal_space": {
      "latent": false
    },
    "l2": 1e-4,
    "dynamics_penalty": 0.0,
    "entropy_penalty": 0.1,
    "dropout": 0.0,
    "gamma": 0.95,
    "target_frequency": 5,
    "batch_size": 5,
    "latent_depth": 8,
    "num_channels": 256,
    "num_towers": 3,
    "num_dense": 2,
    "actor_size": 2,
    "size_dense": 32,
    "activation": "elu",
    "support_size": 15,
    "observation_length": 1
  }
}